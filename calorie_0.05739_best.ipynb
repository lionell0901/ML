{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e6071784-0fa1-434b-bc00-9e5b3213d082",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c1ecb503-04e3-4d75-919b-da15cd9e210c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(750000, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Heart_Rate</th>\n",
       "      <th>Body_Temp</th>\n",
       "      <th>Calories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>36</td>\n",
       "      <td>189.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>64</td>\n",
       "      <td>163.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>39.7</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>51</td>\n",
       "      <td>161.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>39.8</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>20</td>\n",
       "      <td>192.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>40.7</td>\n",
       "      <td>140.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>female</td>\n",
       "      <td>38</td>\n",
       "      <td>166.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>40.6</td>\n",
       "      <td>146.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id     Sex  Age  Height  Weight  Duration  Heart_Rate  Body_Temp  Calories\n",
       "0   0    male   36   189.0    82.0      26.0       101.0       41.0     150.0\n",
       "1   1  female   64   163.0    60.0       8.0        85.0       39.7      34.0\n",
       "2   2  female   51   161.0    64.0       7.0        84.0       39.8      29.0\n",
       "3   3    male   20   192.0    90.0      25.0       105.0       40.7     140.0\n",
       "4   4  female   38   166.0    61.0      25.0       102.0       40.6     146.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "df = pd.read_csv(\"/Users/nelllio/Desktop/Machine_Learning/playground-series/train.csv\")\n",
    "print(df.shape)\n",
    "df.head()\n",
    "#df ë³€ìˆ˜ ì§€ì • í›„ head()ë¥¼ í†µí•´ 5í–‰ê¹Œì§€ ë°ì´í„° í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35fdf56c-1a3d-470e-9364-e7cc14b23a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 750000 entries, 0 to 749999\n",
      "Data columns (total 9 columns):\n",
      " #   Column      Non-Null Count   Dtype  \n",
      "---  ------      --------------   -----  \n",
      " 0   id          750000 non-null  int64  \n",
      " 1   Sex         750000 non-null  object \n",
      " 2   Age         750000 non-null  int64  \n",
      " 3   Height      750000 non-null  float64\n",
      " 4   Weight      750000 non-null  float64\n",
      " 5   Duration    750000 non-null  float64\n",
      " 6   Heart_Rate  750000 non-null  float64\n",
      " 7   Body_Temp   750000 non-null  float64\n",
      " 8   Calories    750000 non-null  float64\n",
      "dtypes: float64(6), int64(2), object(1)\n",
      "memory usage: 51.5+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "train = df.info()\n",
    "print(train)\n",
    "# countì— non-nullë¡œ ê²°ì¸¡ì¹˜ ì—†ëŠ” ê²ƒ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c8cb45f5-2cd0-41dc-9509-072927198979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007414 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2143\n",
      "[LightGBM] [Info] Number of data points in the train set: 600000, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 4.140724\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013406 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2143\n",
      "[LightGBM] [Info] Number of data points in the train set: 600000, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 4.141163\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052867 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2141\n",
      "[LightGBM] [Info] Number of data points in the train set: 600000, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 4.141876\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.039616 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2146\n",
      "[LightGBM] [Info] Number of data points in the train set: 600000, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 4.141466\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.072395 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2144\n",
      "[LightGBM] [Info] Number of data points in the train set: 600000, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 4.140493\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.057572 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2140\n",
      "[LightGBM] [Info] Number of data points in the train set: 480000, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 4.140974\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009385 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2144\n",
      "[LightGBM] [Info] Number of data points in the train set: 480000, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 4.141961\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.059458 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2141\n",
      "[LightGBM] [Info] Number of data points in the train set: 480000, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 4.142021\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.135473 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2141\n",
      "[LightGBM] [Info] Number of data points in the train set: 480000, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 4.141786\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.066616 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2143\n",
      "[LightGBM] [Info] Number of data points in the train set: 480000, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 4.140854\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028147 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2143\n",
      "[LightGBM] [Info] Number of data points in the train set: 480000, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 4.140854\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.073700 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2142\n",
      "[LightGBM] [Info] Number of data points in the train set: 480000, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 4.140429\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010567 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2140\n",
      "[LightGBM] [Info] Number of data points in the train set: 480000, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 4.141604\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.057533 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2145\n",
      "[LightGBM] [Info] Number of data points in the train set: 480000, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 4.141523\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005412 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2146\n",
      "[LightGBM] [Info] Number of data points in the train set: 480000, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 4.140466\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.137266 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2144\n",
      "[LightGBM] [Info] Number of data points in the train set: 480000, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 4.142023\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.127233 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2144\n",
      "[LightGBM] [Info] Number of data points in the train set: 480000, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 4.141844\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017887 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2141\n",
      "[LightGBM] [Info] Number of data points in the train set: 480000, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 4.142997\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035144 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2146\n",
      "[LightGBM] [Info] Number of data points in the train set: 480000, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 4.141589\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.107099 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2146\n",
      "[LightGBM] [Info] Number of data points in the train set: 480000, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 4.142381\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008456 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2144\n",
      "[LightGBM] [Info] Number of data points in the train set: 480000, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 4.140997\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008468 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2144\n",
      "[LightGBM] [Info] Number of data points in the train set: 480000, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 4.140839\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008691 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2141\n",
      "[LightGBM] [Info] Number of data points in the train set: 480000, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 4.141706\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010626 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2147\n",
      "[LightGBM] [Info] Number of data points in the train set: 480000, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 4.141103\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.100284 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2144\n",
      "[LightGBM] [Info] Number of data points in the train set: 480000, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 4.140275\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046600 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2144\n",
      "[LightGBM] [Info] Number of data points in the train set: 480000, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 4.139376\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012175 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2144\n",
      "[LightGBM] [Info] Number of data points in the train set: 480000, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 4.140140\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.071441 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2141\n",
      "[LightGBM] [Info] Number of data points in the train set: 480000, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 4.141052\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.053939 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2148\n",
      "[LightGBM] [Info] Number of data points in the train set: 480000, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 4.140534\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.104489 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2144\n",
      "[LightGBM] [Info] Number of data points in the train set: 480000, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 4.139282\n",
      "ğŸ“Š 5-fold CV RMSLE: 0.0171 Â± 0.0001\n",
      "\n",
      "ğŸ“š ëª¨ë¸ í•™ìŠµ ì¤‘...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017113 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2146\n",
      "[LightGBM] [Info] Number of data points in the train set: 480000, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 4.141291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018884 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2144\n",
      "[LightGBM] [Info] Number of data points in the train set: 480000, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 4.142413\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.059966 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.075700 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Number of data points in the train set: 480000, number of used features: 14\n",
      "[LightGBM] [Info] Total Bins 2144\n",
      "[LightGBM] [Info] Number of data points in the train set: 480000, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 4.141428\n",
      "[LightGBM] [Info] Start training from score 4.140559\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020163 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2145\n",
      "[LightGBM] [Info] Number of data points in the train set: 480000, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 4.140125\n",
      "ğŸ¯ Hold-out RMSLE: 0.0596\n",
      "\n",
      "ğŸš€ Kaggle ì œì¶œ íŒŒì¼ ìƒì„± ì¤‘...\n",
      "ğŸ“š ì „ì²´ í›ˆë ¨ ë°ì´í„°ë¡œ ìµœì¢… ëª¨ë¸ í•™ìŠµ ì¤‘...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014306 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2145\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010621 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2147\n",
      "[LightGBM] [Info] Number of data points in the train set: 600000, number of used features: 14\n",
      "[LightGBM] [Info] Number of data points in the train set: 600000, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 4.142215\n",
      "[LightGBM] [Info] Start training from score 4.140934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.116368 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2145\n",
      "[LightGBM] [Info] Number of data points in the train set: 600000, number of used features: 14\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015453 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2142\n",
      "[LightGBM] [Info] Number of data points in the train set: 600000, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 4.141530\n",
      "[LightGBM] [Info] Start training from score 4.140089\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.055804 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2143\n",
      "[LightGBM] [Info] Number of data points in the train set: 600000, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 4.140954\n",
      "ğŸ”® í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡ ì¤‘...\n",
      "âœ… Submission íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤: /Users/nelllio/Desktop/Machine_Learning/playground-series/submission.csv\n",
      "ğŸ“Š ì˜ˆì¸¡ëœ ì¹¼ë¡œë¦¬ ë²”ìœ„: 1.04 ~ 295.20\n",
      "ğŸ“Š í‰ê·  ì˜ˆì¸¡ ì¹¼ë¡œë¦¬: 88.18\n",
      "ğŸ“‹ Submission í˜•íƒœ:\n",
      "       id    Calories\n",
      "0  750000   27.653635\n",
      "1  750001  107.592008\n",
      "2  750002   87.117329\n",
      "3  750003  126.170766\n",
      "4  750004   76.208452\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# 0. ë¼ì´ë¸ŒëŸ¬ë¦¬ (ë™ì¼)\n",
    "# ===============================\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "# ===============================\n",
    "# 1. ë°ì´í„° & FE (ë™ì¼)\n",
    "# ===============================\n",
    "\n",
    "def create_golden_features(df):\n",
    "    df = df.copy()\n",
    "    df['Duration_x_HeartRate']   = df['Duration'] * df['Heart_Rate']\n",
    "    df['Age_adjusted_HeartRate'] = df['Heart_Rate'] / (df['Age'] + 1)\n",
    "    df['BMI']                    = df['Weight'] / (df['Height'] / 100) ** 2\n",
    "    df['Metabolic_Intensity']    = df['Heart_Rate'] * df['Body_Temp']\n",
    "    df['Steps_per_min']          = df['Heart_Rate'] / (df['Duration'] / 60)\n",
    "    df['Weight_to_Age']          = df['Weight'] / (df['Age'] + 1)\n",
    "    df['HeartRate_to_BMI']       = df['Heart_Rate'] / (df['BMI'] + 1)\n",
    "    df['Sex'] = df['Sex'].map({'male': 0, 'female': 1})\n",
    "    return df\n",
    "\n",
    "df = create_golden_features(df)\n",
    "features = [\n",
    "    'Duration','Heart_Rate','BMI','Body_Temp',\n",
    "    'Duration_x_HeartRate','Metabolic_Intensity',\n",
    "    'Age','Height','Weight',\n",
    "    'Steps_per_min','Age_adjusted_HeartRate',\n",
    "    'Weight_to_Age','HeartRate_to_BMI','Sex'\n",
    "]\n",
    "X, y = df[features], df['Calories']\n",
    "\n",
    "# ===============================\n",
    "# 2. RMSLE ìŠ¤ì½”ì–´ëŸ¬ + 5-fold CV\n",
    "# ===============================\n",
    "def rmsle(y_true, y_pred):\n",
    "    y_pred = np.maximum(y_pred, 0.1)                      # log ì•ˆì •í™”\n",
    "    return np.sqrt(mean_squared_error(np.log1p(y_true),\n",
    "                                      np.log1p(y_pred)))\n",
    "\n",
    "rmsle_scorer = make_scorer(rmsle, greater_is_better=False)  # ìŒìˆ˜ ë°˜í™˜(ì‘ì„ìˆ˜ë¡ ì¢‹ìŒ)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# ===============================\n",
    "# 3. Base learner â€“ ë¯¸ì„¸ íŠœë‹\n",
    "#    (n_estimators â†‘, learning_rate â†“)\n",
    "# ===============================\n",
    "xgb = XGBRegressor(\n",
    "        n_estimators=500, learning_rate=0.05,\n",
    "        max_depth=6, subsample=0.9, colsample_bytree=0.9,\n",
    "        n_jobs=-1, random_state=42, verbosity=0)\n",
    "\n",
    "lgb = LGBMRegressor(\n",
    "        n_estimators=500, learning_rate=0.05,\n",
    "        max_depth=-1, subsample=0.9, colsample_bytree=0.9,\n",
    "        n_jobs=-1, random_state=42)\n",
    "\n",
    "cat = CatBoostRegressor(\n",
    "        n_estimators=500, learning_rate=0.05,\n",
    "        depth=8, l2_leaf_reg=3,\n",
    "        verbose=0, random_state=42)\n",
    "\n",
    "# ===============================\n",
    "# 4. ìŠ¤íƒœí‚¹ ì •ì˜ (ë™ì¼)\n",
    "# ===============================\n",
    "stack = StackingRegressor(\n",
    "    estimators=[('xgb', xgb), ('lgb', lgb), ('cat', cat)],\n",
    "    final_estimator=RidgeCV(),\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# ===============================\n",
    "# 5-1. êµì°¨ê²€ì¦ RMSLE í™•ì¸\n",
    "# ===============================\n",
    "cv_scores = cross_val_score(stack, X, np.log1p(y),   # log1p ë³€í™˜ â‡ ë™ì¼ ê¸°ì¤€\n",
    "                            cv=kf, scoring=rmsle_scorer,\n",
    "                            n_jobs=-1)\n",
    "print(f\"ğŸ“Š 5-fold CV RMSLE: {(-cv_scores.mean()):.4f} Â± {cv_scores.std():.4f}\")\n",
    "\n",
    "# ===============================\n",
    "# 5-2. í™€ë“œì•„ì›ƒ í•™ìŠµ/í‰ê°€\n",
    "# ===============================\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42)\n",
    "print(\"\\nğŸ“š ëª¨ë¸ í•™ìŠµ ì¤‘...\")\n",
    "stack.fit(X_train, np.log1p(y_train))\n",
    "y_pred = np.expm1(stack.predict(X_val))\n",
    "print(f\"ğŸ¯ Hold-out RMSLE: {rmsle(y_val, y_pred):.4f}\")\n",
    "\n",
    "# ===============================\n",
    "# 6. Kaggle ì œì¶œìš© ì½”ë“œ ì¶”ê°€\n",
    "# ===============================\n",
    "print(\"\\nğŸš€ Kaggle ì œì¶œ íŒŒì¼ ìƒì„± ì¤‘...\")\n",
    "\n",
    "# 6-1. í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ\n",
    "test_df = pd.read_csv(\"/Users/nelllio/Desktop/Machine_Learning/playground-series/test.csv\")\n",
    "\n",
    "# 6-2. í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— ë™ì¼í•œ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ì ìš©\n",
    "test_df = create_golden_features(test_df)\n",
    "X_test = test_df[features]\n",
    "\n",
    "# 6-3. ì „ì²´ í›ˆë ¨ ë°ì´í„°ë¡œ ìµœì¢… ëª¨ë¸ í•™ìŠµ\n",
    "print(\"ğŸ“š ì „ì²´ í›ˆë ¨ ë°ì´í„°ë¡œ ìµœì¢… ëª¨ë¸ í•™ìŠµ ì¤‘...\")\n",
    "stack.fit(X, np.log1p(y))\n",
    "\n",
    "# 6-4. í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡\n",
    "print(\"ğŸ”® í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡ ì¤‘...\")\n",
    "test_predictions = np.expm1(stack.predict(X_test))\n",
    "\n",
    "# 6-5. submission íŒŒì¼ ìƒì„±\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_df['id'],\n",
    "    'Calories': test_predictions\n",
    "})\n",
    "\n",
    "# 6-6. submission íŒŒì¼ ì €ì¥\n",
    "submission_path = \"/Users/nelllio/Desktop/Machine_Learning/playground-series/submission.csv\"\n",
    "submission.to_csv(submission_path, index=False)\n",
    "\n",
    "print(f\"âœ… Submission íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤: {submission_path}\")\n",
    "print(f\"ğŸ“Š ì˜ˆì¸¡ëœ ì¹¼ë¡œë¦¬ ë²”ìœ„: {test_predictions.min():.2f} ~ {test_predictions.max():.2f}\")\n",
    "print(f\"ğŸ“Š í‰ê·  ì˜ˆì¸¡ ì¹¼ë¡œë¦¬: {test_predictions.mean():.2f}\")\n",
    "print(f\"ğŸ“‹ Submission í˜•íƒœ:\")\n",
    "print(submission.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4691c700-2c09-44c1-847b-3e854248afc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 11893428,
     "sourceId": 91716,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
